{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_name_list = ['business','entertainment','politics','sport','tech']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取得所有文本的entity\n",
    "目的是要之後將所有entity放到DBpedia Rest API，找到所有entity在所選取的property的所有value。將這些entity的property的value事先存下來，之後要應用只要查詢即可。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_entities_dict = {}\n",
    "\n",
    "for topic_name in topic_name_list:\n",
    "    \n",
    "    class_news_entities_list = os.listdir(\"./all_entities/\"+topic_name)\n",
    "    \n",
    "    for class_news_name in class_news_entities_list:\n",
    "        if class_news_name != \".ipynb_checkpoints\":\n",
    "            \n",
    "            class_news_entities_open = open(os.path.join(\"./all_entities/\",topic_name,class_news_name),\"r\")\n",
    "            class_news_entities = eval(class_news_entities_open.read())\n",
    "            \n",
    "            for entity in class_news_entities.keys():\n",
    "                \n",
    "                if entity in all_entities_dict:\n",
    "                    all_entities_dict[entity] = all_entities_dict[entity] + class_news_entities[entity]\n",
    "\n",
    "                else:\n",
    "                    all_entities_dict[entity] = class_news_entities[entity]\n",
    "                    \n",
    "f = open(\"./all_entities.txt\",\"w\")\n",
    "f.write(str(all_entities_dict))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取得各個class的所有entities\n",
    "從切割好的各個類別的80%文本，找到這些文本的所有entity。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_name in topic_name_list:\n",
    "    \n",
    "    class_news_name_list_path = \"./class_test_news_name_list/\"+topic_name+\"_class_name_list.txt\"\n",
    "    class_news_name_list_open = open(class_news_name_list_path, \"r\")\n",
    "    class_news_name_list = eval(class_news_name_list_open.read())\n",
    "    \n",
    "    class_all_entities_dict = {}\n",
    "    \n",
    "    for class_news_name in class_news_name_list:\n",
    "        \n",
    "        class_news_entities_path = os.path.join(\"all_entities\", topic_name, class_news_name)\n",
    "        class_news_entities_open = open(class_news_entities_path, \"r\")\n",
    "        class_news_entities_dict = eval(class_news_entities_open.read())\n",
    "        \n",
    "        for entity in class_news_entities_dict.keys():\n",
    "            if entity in class_all_entities_dict:\n",
    "                class_all_entities_dict[entity] = class_all_entities_dict[entity] + class_news_entities_dict[entity]\n",
    "                \n",
    "            else:\n",
    "                class_all_entities_dict[entity] = class_news_entities_dict[entity]\n",
    "                \n",
    "    g = open(\"./class_entities/\"+topic_name+\"class_entities.txt\",\"w\")\n",
    "    g.write(str(class_all_entities_dict))\n",
    "    g.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 取得所有test，集中到一個資料夾內"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for topic_name in topic_name_list:\n",
    "    \n",
    "    test_news_name_list_path = \"./class_test_news_name_list/\"+topic_name+\"_test_name_list.txt\"\n",
    "    test_news_name_list_open = open(test_news_name_list_path, \"r\")\n",
    "    test_news_name_list = eval(test_news_name_list_open.read())\n",
    "    \n",
    "    for test_news_name in test_news_name_list:\n",
    "        test_news_entities_path = os.path.join(\"all_entities\", topic_name, test_news_name)\n",
    "        #print(test_news_entities_path)\n",
    "        \n",
    "        new_test_news_name = topic_name+\"_\"+test_news_name\n",
    "        #print(new_test_news_name)\n",
    "        \n",
    "        new_test_news_entities_path = \"./test_entities/\"+new_test_news_name\n",
    "        #print(new_test_news_entities_path)\n",
    "        \n",
    "        shutil.copyfile(test_news_entities_path, new_test_news_entities_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
